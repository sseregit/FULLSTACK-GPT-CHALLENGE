from datetime import datetime

import streamlit as st
from langchain_community.document_loaders import WebBaseLoader
# Wikipedia
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from langchain_community.utilities import WikipediaAPIWrapper
from openai import OpenAI
from openai.types.beta.assistant_stream_event import ThreadRunRequiresAction, ThreadMessageDelta
import json


# load_dotenv()

def search_wikipedia(parameters):
    api_wrapper = WikipediaAPIWrapper(top_k_results=2)
    tool = WikipediaQueryRun(api_wrapper=api_wrapper)
    return tool._run(parameters["query"])


def search_duckduckgo(parameters):
    duckduck_api_wrapper = DuckDuckGoSearchAPIWrapper(time="m")
    docs = duckduck_api_wrapper.results(parameters["query"], max_results=1)
    links = []

    for doc in docs:
        links.append(doc["link"])

    loader = WebBaseLoader(
        web_path=links,
        bs_get_text_kwargs={
            "strip": True,
        }
    )

    load = loader.load()
    return "\n".join([content.page_content for content in load])


def save_file(parameters):
    now = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
    filename = f"research_result_{now}.txt"
    with open(filename, 'w', encoding="utf-8") as f:
        f.write(parameters["content"] + "\n")
    return parameters["content"]


functions = [
    {
        "type": "function",
        "function": {
            "name": "search_wikipedia",
            "description": "queryì— ëŒ€í•œ ë‹µì„ Wikipediaë¥¼ í™œìš©í•´ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The query you will search",
                    },
                },
                "required": ["query"],
            },

        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_duckduckgo",
            "description": "queryì— ëŒ€í•œ ë‹µì„ DuckDuckGoë¥¼ í™œìš©í•´ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The query you will search",
                    },
                },
                "required": ["query"]
            },

        }
    },
    {
        "type": "function",
        "function": {
            "name": "save_file",
            "description": """ ë¦¬ì„œì¹˜ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ë°˜ë“œì‹œ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
                            Wikipediaì™€ DuckDuckGoì—ì„œ ìˆ˜ì§‘í•œ ëª¨ë“  ì •ë³´ë¥¼ ì •ë¦¬í•˜ì—¬ content íŒŒë¼ë¯¸í„°ì— ì „ë‹¬í•˜ë©´ ìë™ìœ¼ë¡œ íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
                            ì£¼ì˜: contentì—ëŠ” íŒŒì¼ëª…ì´ ì•„ë‹Œ, ì‹¤ì œë¡œ ì¡°ì‚¬í•œ ë‚´ìš© ìš”ì•½/ì •ë¦¬í•´ì„œ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.
                            """,
            "parameters": {
                "type": "object",
                "properties": {
                    "content": {
                        "type": "string",
                        "description": "ê²€ìƒ‰ ë„êµ¬ë“¤ë¡œë¶€í„° ìˆ˜ì§‘í•œ ì „ì²´ ë¦¬ì„œì¹˜ ë‚´ìš©ê³¼ ê²°ê³¼ë¥¼ ì—¬ê¸°ì— ì „ë‹¬í•˜ì„¸ìš”. íŒŒì¼ëª…ì´ ì•„ë‹Œ ì‹¤ì œ ì¡°ì‚¬í•œ ë‚´ìš© ì „ì²´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.",
                    },
                },
                "required": ["content"]
            },

        }
    },
]

functions_map = {
    "search_wikipedia": search_wikipedia,
    "search_duckduckgo": search_duckduckgo,
    "save_file": save_file,
}


@st.cache_data(show_spinner="Generating... Assistant....")
def create_assistant(openai_api_key):
    assistant = client.beta.assistants.create(
        name="search assistant",
        instructions="""
              ë‹¹ì‹ ì€ ì£¼ì œì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

              **í•„ìˆ˜ ì›Œí¬í”Œë¡œìš°:**
              1. ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ Wikipediaì™€ DuckDuckGoë¡œ ì¡°ì‚¬
              2. ì¡°ì‚¬ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ê³  ì •ë¦¬
              3. save_file ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜ë“œì‹œ íŒŒì¼ì— ì €ì¥
              4. "âœ“ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:
              research_result_YYYY-MM-DDTHH:MM:SS.txt" í˜•ì‹ìœ¼ë¡œ ì•Œë¦¼
              5. ì €ì¥ëœ ë‚´ìš©ì˜ ìš”ì•½ì„ ì‚¬ìš©ìì—ê²Œ ì œê³µ

              **ì£¼ì˜:**
              - ëª¨ë“  ì¡°ì‚¬ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ì•¼ í•¨
              - íŒŒì¼ ì €ì¥ ì—†ì´ ì¡°ì‚¬ë§Œ í•˜ë©´ ì•ˆ ë¨
              """,
        model="gpt-4-turbo",
        tools=functions,
    )

    return assistant


st.set_page_config(
    page_title="OpenAI Assistants (Graduation Project)",
    page_icon="ğŸ‘",
)

with st.sidebar:
    openai_api_key = st.text_input(
        "Enter your OpenAI API Key",
        placeholder="sk-...",
        key="openai_api_key",
    )
    st.markdown("[Github](https://github.com/sseregit/FULLSTACK-GPT-CHALLENGE)")

st.session_state["messages"] = []

if openai_api_key:
    try:
        client = OpenAI(api_key=openai_api_key)
        assistant = create_assistant(openai_api_key)

        if assistant:
            st.chat_message("assistant").write("Please search for the keyword.")

            if user_input := st.chat_input():
                st.chat_message("user").write(user_input)

                with client.beta.threads.create_and_run_stream(
                    assistant_id=assistant.id,
                    thread={
                        "messages": [{
                            "role": "user",
                            "content": user_input,
                        }]
                    },
                ) as stream:
                    for event in stream:
                        if isinstance(event, ThreadRunRequiresAction):
                            run = event.data
                            outputs = []
                            for action in run.required_action.submit_tool_outputs.tool_calls:
                                action_id = action.id
                                function = action.function
                                outputs.append(
                                    {
                                        "output": functions_map[function.name](json.loads(function.arguments)),
                                        "tool_call_id": action_id,
                                    }
                                )
                            with client.beta.threads.runs.submit_tool_outputs_stream(tool_outputs=outputs,
                                                                                     run_id=run.id,
                                                                                     thread_id=run.thread_id) as next_stream:
                                for followup_event in next_stream:
                                    if isinstance(followup_event, ThreadRunRequiresAction):
                                        run = followup_event.data
                                        outputs = []
                                        for action in run.required_action.submit_tool_outputs.tool_calls:
                                            action_id = action.id
                                            function = action.function
                                            outputs.append(
                                                {
                                                    "output": functions_map[action.function.name](json.loads(action.function.arguments)),
                                                    "tool_call_id": action.id,
                                                }
                                            )
                                        with client.beta.threads.runs.submit_tool_outputs_stream(tool_outputs=outputs,
                                                                                                 run_id=run.id,
                                                                                                 thread_id=run.thread_id) as next_stream:
                                            full_text = ""
                                            with st.chat_message("ai"):
                                                ai_placeholder = st.empty()
                                                for followup_event in next_stream:
                                                    if isinstance(followup_event, ThreadMessageDelta):
                                                        delta_text = followup_event.data.delta.content[0].text.value
                                                        full_text += delta_text
                                                        ai_placeholder.markdown(full_text)

    except Exception as e:
        st.error(f"please change openai_api_key {e}")
        del st.session_state["openai_api_key"]
